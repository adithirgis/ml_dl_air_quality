21/10/01 10:53:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/10/01 10:53:39 INFO SparkContext: Running Spark version 2.4.3
21/10/01 10:53:39 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/10/01 10:53:39 INFO SparkContext: Submitted application: sparklyr
21/10/01 10:53:39 INFO SecurityManager: Changing view acls to: Dell
21/10/01 10:53:39 INFO SecurityManager: Changing modify acls to: Dell
21/10/01 10:53:39 INFO SecurityManager: Changing view acls groups to: 
21/10/01 10:53:39 INFO SecurityManager: Changing modify acls groups to: 
21/10/01 10:53:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Dell); groups with view permissions: Set(); users  with modify permissions: Set(Dell); groups with modify permissions: Set()
21/10/01 10:53:39 INFO Utils: Successfully started service 'sparkDriver' on port 53119.
21/10/01 10:53:39 INFO SparkEnv: Registering MapOutputTracker
21/10/01 10:53:39 INFO SparkEnv: Registering BlockManagerMaster
21/10/01 10:53:39 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/01 10:53:39 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/01 10:53:39 INFO DiskBlockManager: Created local directory at C:\Users\Dell\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\blockmgr-cc968fe8-b922-4ec9-872d-d3734b9cdda1
21/10/01 10:53:39 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/10/01 10:53:39 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/01 10:53:39 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/Dell/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/local]. Please check your configured local directories.
21/10/01 10:53:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/01 10:53:40 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
21/10/01 10:53:40 INFO SparkContext: Added JAR file:///D:/R/library/rsparkling/java/sparkling_water_assembly.jar at spark://127.0.0.1:53119/jars/sparkling_water_assembly.jar with timestamp 1633065820036
21/10/01 10:53:40 INFO SparkContext: Added JAR file:/D:/R/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://127.0.0.1:53119/jars/sparklyr-2.4-2.11.jar with timestamp 1633065820038
21/10/01 10:53:40 INFO Executor: Starting executor ID driver on host localhost
21/10/01 10:53:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53160.
21/10/01 10:53:40 INFO NettyBlockTransferService: Server created on 127.0.0.1:53160
21/10/01 10:53:40 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/01 10:53:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53160, None)
21/10/01 10:53:40 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53160 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 53160, None)
21/10/01 10:53:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53160, None)
21/10/01 10:53:40 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53160, None)
21/10/01 10:53:40 INFO SharedState: loading hive config file: file:/C:/Users/Dell/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/10/01 10:53:40 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Dell/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Dell/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive').
21/10/01 10:53:40 INFO SharedState: Warehouse path is 'C:/Users/Dell/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive'.
21/10/01 10:53:41 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/10/01 10:54:07 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/10/01 10:54:08 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/10/01 10:54:08 INFO ObjectStore: ObjectStore, initialize called
21/10/01 10:54:08 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/10/01 10:54:08 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/10/01 10:54:10 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/10/01 10:54:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/10/01 10:54:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/10/01 10:54:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/10/01 10:54:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/10/01 10:54:13 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/10/01 10:54:13 INFO ObjectStore: Initialized ObjectStore
21/10/01 10:54:13 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/10/01 10:54:13 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/10/01 10:54:13 INFO HiveMetaStore: Added admin role in metastore
21/10/01 10:54:13 INFO HiveMetaStore: Added public role in metastore
21/10/01 10:54:13 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/10/01 10:54:13 INFO HiveMetaStore: 0: get_all_databases
21/10/01 10:54:13 INFO audit: ugi=Dell	ip=unknown-ip-addr	cmd=get_all_databases	
21/10/01 10:54:13 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/10/01 10:54:13 INFO audit: ugi=Dell	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/10/01 10:54:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/10/01 10:54:14 INFO SessionState: Created local directory: C:/Users/Dell/AppData/Local/Temp/edc42f89-5df5-43c6-a28f-19a99fdc75f0_resources
21/10/01 10:54:14 INFO SessionState: Created HDFS directory: C:/Users/Dell/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/Dell/edc42f89-5df5-43c6-a28f-19a99fdc75f0
21/10/01 10:54:14 INFO SessionState: Created local directory: C:/Users/Dell/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/edc42f89-5df5-43c6-a28f-19a99fdc75f0
21/10/01 10:54:14 INFO SessionState: Created HDFS directory: C:/Users/Dell/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/Dell/edc42f89-5df5-43c6-a28f-19a99fdc75f0/_tmp_space.db
21/10/01 10:54:14 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is C:/Users/Dell/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive
21/10/01 10:54:14 INFO HiveMetaStore: 0: get_database: default
21/10/01 10:54:14 INFO audit: ugi=Dell	ip=unknown-ip-addr	cmd=get_database: default	
21/10/01 10:54:14 INFO HiveMetaStore: 0: get_database: global_temp
21/10/01 10:54:14 INFO audit: ugi=Dell	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/10/01 10:54:14 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/10/01 10:54:14 INFO HiveMetaStore: 0: get_database: default
21/10/01 10:54:14 INFO audit: ugi=Dell	ip=unknown-ip-addr	cmd=get_database: default	
21/10/01 10:54:14 INFO HiveMetaStore: 0: get_database: default
21/10/01 10:54:14 INFO audit: ugi=Dell	ip=unknown-ip-addr	cmd=get_database: default	
21/10/01 10:54:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/10/01 10:54:14 INFO audit: ugi=Dell	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/10/01 10:54:15 INFO CodeGenerator: Code generated in 342.825 ms
21/10/01 10:54:16 INFO CodeGenerator: Code generated in 32.3763 ms
21/10/01 10:54:16 INFO CodeGenerator: Code generated in 14.5925 ms
21/10/01 10:54:16 INFO SparkContext: Starting job: count at utils.scala:24
21/10/01 10:54:16 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:24)
21/10/01 10:54:16 INFO DAGScheduler: Got job 0 (count at utils.scala:24) with 1 output partitions
21/10/01 10:54:16 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:24)
21/10/01 10:54:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/10/01 10:54:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/10/01 10:54:16 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:24), which has no missing parents
21/10/01 10:54:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/10/01 10:54:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/10/01 10:54:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53160 (size: 4.2 KB, free: 912.3 MB)
21/10/01 10:54:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/10/01 10:54:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/01 10:54:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/10/01 10:54:17 INFO ContextCleaner: Cleaned accumulator 1
21/10/01 10:54:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/10/01 10:54:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/10/01 10:54:17 INFO Executor: Fetching spark://127.0.0.1:53119/jars/sparklyr-2.4-2.11.jar with timestamp 1633065820038
21/10/01 10:54:17 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:53119 after 36 ms (0 ms spent in bootstraps)
21/10/01 10:54:17 INFO Utils: Fetching spark://127.0.0.1:53119/jars/sparklyr-2.4-2.11.jar to C:\Users\Dell\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-800ad9fb-18b2-4733-bec2-51448c8c2fa7\userFiles-22d6f3b9-8282-412f-84ff-868aa3a042f4\fetchFileTemp1354384203905676250.tmp
21/10/01 10:54:17 INFO Executor: Adding file:/C:/Users/Dell/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/local/spark-800ad9fb-18b2-4733-bec2-51448c8c2fa7/userFiles-22d6f3b9-8282-412f-84ff-868aa3a042f4/sparklyr-2.4-2.11.jar to class loader
21/10/01 10:54:17 INFO Executor: Fetching spark://127.0.0.1:53119/jars/sparkling_water_assembly.jar with timestamp 1633065820036
21/10/01 10:54:17 INFO Utils: Fetching spark://127.0.0.1:53119/jars/sparkling_water_assembly.jar to C:\Users\Dell\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-800ad9fb-18b2-4733-bec2-51448c8c2fa7\userFiles-22d6f3b9-8282-412f-84ff-868aa3a042f4\fetchFileTemp7805484015544322826.tmp
21/10/01 10:54:21 INFO Executor: Adding file:/C:/Users/Dell/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/local/spark-800ad9fb-18b2-4733-bec2-51448c8c2fa7/userFiles-22d6f3b9-8282-412f-84ff-868aa3a042f4/sparkling_water_assembly.jar to class loader
21/10/01 10:54:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1542 bytes result sent to driver
21/10/01 10:54:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5065 ms on localhost (executor driver) (1/1)
21/10/01 10:54:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/10/01 10:54:22 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:24) finished in 5.471 s
21/10/01 10:54:22 INFO DAGScheduler: looking for newly runnable stages
21/10/01 10:54:22 INFO DAGScheduler: running: Set()
21/10/01 10:54:22 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/10/01 10:54:22 INFO DAGScheduler: failed: Set()
21/10/01 10:54:22 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:24), which has no missing parents
21/10/01 10:54:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/10/01 10:54:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/10/01 10:54:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53160 (size: 3.8 KB, free: 912.3 MB)
21/10/01 10:54:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/10/01 10:54:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/01 10:54:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/10/01 10:54:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/10/01 10:54:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/10/01 10:54:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/10/01 10:54:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
21/10/01 10:54:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1775 bytes result sent to driver
21/10/01 10:54:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 88 ms on localhost (executor driver) (1/1)
21/10/01 10:54:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/10/01 10:54:22 INFO DAGScheduler: ResultStage 1 (count at utils.scala:24) finished in 0.103 s
21/10/01 10:54:22 INFO DAGScheduler: Job 0 finished: count at utils.scala:24, took 5.699973 s
21/10/01 10:54:22 INFO HiveMetaStore: 0: get_database: default
21/10/01 10:54:22 INFO audit: ugi=Dell	ip=unknown-ip-addr	cmd=get_database: default	
21/10/01 10:54:22 INFO HiveMetaStore: 0: get_database: default
21/10/01 10:54:22 INFO audit: ugi=Dell	ip=unknown-ip-addr	cmd=get_database: default	
21/10/01 10:54:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/10/01 10:54:22 INFO audit: ugi=Dell	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/10/01 10:54:22 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:53160 in memory (size: 3.8 KB, free: 912.3 MB)
21/10/01 10:54:23 INFO SparkContext: Starting job: count at utils.scala:24
21/10/01 10:54:23 INFO DAGScheduler: Registering RDD 10 (count at utils.scala:24)
21/10/01 10:54:23 INFO DAGScheduler: Got job 1 (count at utils.scala:24) with 1 output partitions
21/10/01 10:54:23 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:24)
21/10/01 10:54:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/10/01 10:54:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/10/01 10:54:23 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[10] at count at utils.scala:24), which has no missing parents
21/10/01 10:54:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/10/01 10:54:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/10/01 10:54:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53160 (size: 4.2 KB, free: 912.3 MB)
21/10/01 10:54:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/10/01 10:54:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[10] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/01 10:54:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/10/01 10:54:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/10/01 10:54:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/10/01 10:54:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1499 bytes result sent to driver
21/10/01 10:54:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 82 ms on localhost (executor driver) (1/1)
21/10/01 10:54:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/10/01 10:54:23 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:24) finished in 0.096 s
21/10/01 10:54:23 INFO DAGScheduler: looking for newly runnable stages
21/10/01 10:54:23 INFO DAGScheduler: running: Set()
21/10/01 10:54:23 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/10/01 10:54:23 INFO DAGScheduler: failed: Set()
21/10/01 10:54:23 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[13] at count at utils.scala:24), which has no missing parents
21/10/01 10:54:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/10/01 10:54:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/10/01 10:54:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53160 (size: 3.8 KB, free: 912.3 MB)
21/10/01 10:54:23 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/10/01 10:54:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/01 10:54:23 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/10/01 10:54:23 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/10/01 10:54:23 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/10/01 10:54:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/10/01 10:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/10/01 10:54:23 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1732 bytes result sent to driver
21/10/01 10:54:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 18 ms on localhost (executor driver) (1/1)
21/10/01 10:54:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/10/01 10:54:23 INFO DAGScheduler: ResultStage 3 (count at utils.scala:24) finished in 0.066 s
21/10/01 10:54:23 INFO DAGScheduler: Job 1 finished: count at utils.scala:24, took 0.174050 s
21/10/01 11:24:52 INFO ContextCleaner: Cleaned accumulator 29
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 90
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 120
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 122
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 102
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 112
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 113
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 110
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 80
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 97
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 131
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 69
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 82
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 130
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 86
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 101
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 109
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 114
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 105
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 75
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 83
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 118
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 81
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 108
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 116
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 66
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 100
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 79
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 87
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 67
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 88
21/10/01 11:24:53 INFO ContextCleaner: Cleaned accumulator 129
21/10/01 11:24:53 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:53160 in memory (size: 4.2 KB, free: 912.3 MB)
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 117
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 76
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 121
21/10/01 11:24:54 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:53160 in memory (size: 3.8 KB, free: 912.3 MB)
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 94
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 89
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 124
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 72
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 77
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 68
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 104
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 84
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 99
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 127
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 125
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 95
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 78
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 98
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 115
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 70
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 91
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 119
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 71
21/10/01 11:24:54 INFO ContextCleaner: Cleaned shuffle 1
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 123
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 106
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 126
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 96
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 128
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 103
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 85
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 74
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 92
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 93
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 73
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 107
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 111
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 44
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 17
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 19
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 51
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 26
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 43
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 40
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 37
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 55
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 62
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 18
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 5
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 10
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 16
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 49
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 38
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 65
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 15
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 24
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 59
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 14
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 41
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 9
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 54
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 58
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 22
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 63
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 13
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 25
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 27
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 61
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 8
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 47
21/10/01 11:24:54 INFO ContextCleaner: Cleaned accumulator 45
21/10/01 11:24:54 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53160 in memory (size: 4.2 KB, free: 912.3 MB)
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 7
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 12
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 3
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 23
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 32
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 56
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 31
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 0
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 39
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 48
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 4
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 64
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 33
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 34
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 28
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 11
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 35
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 30
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 53
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 36
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 20
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 50
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 52
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 42
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 21
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 60
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 2
21/10/01 11:24:55 INFO ContextCleaner: Cleaned shuffle 0
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 46
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 6
21/10/01 11:24:55 INFO ContextCleaner: Cleaned accumulator 57
21/10/01 12:51:03 INFO SparkContext: Invoking stop() from shutdown hook
21/10/01 12:51:12 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
21/10/01 12:51:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/10/01 12:51:22 INFO MemoryStore: MemoryStore cleared
21/10/01 12:51:22 INFO BlockManager: BlockManager stopped
21/10/01 12:51:23 INFO BlockManagerMaster: BlockManagerMaster stopped
21/10/01 12:51:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/10/01 12:51:28 INFO SparkContext: Successfully stopped SparkContext
21/10/01 12:51:28 INFO ShutdownHookManager: Shutdown hook called
21/10/01 12:51:29 INFO ShutdownHookManager: Deleting directory C:\Users\Dell\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-800ad9fb-18b2-4733-bec2-51448c8c2fa7
21/10/01 12:51:29 INFO ShutdownHookManager: Deleting directory C:\Users\Dell\AppData\Local\Temp\spark-dc14b230-bde0-491d-9306-b1a55e2f49cf
